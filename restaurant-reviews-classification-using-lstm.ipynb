{"cells":[{"metadata":{},"cell_type":"markdown","source":" # Classification of Restaurant Reviews using two-layers LSTM with GloVe Embedding."},{"metadata":{},"cell_type":"markdown","source":"This notebook is mainly a practice workbook by me, a machine learning novice. Kindly inform me if you find any errors/mistakes here."},{"metadata":{},"cell_type":"markdown","source":"*Let's import necessary packages and libraries here.*"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sb\nimport matplotlib.pyplot as plt\nimport string\nimport nltk\nfrom nltk.sentiment import SentimentIntensityAnalyzer\nimport re\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.models import Sequential\nfrom keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional, SpatialDropout1D\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*Reading the CSV file and placing it in a dataframe for ease of use.*"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.DataFrame(pd.read_csv('/kaggle/input/restaurant-reviews-in-dhaka-bangladesh/reviews.csv'))\npd.set_option('display.max_colwidth',150)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*As there are too many null values I am dropping those two columns.*"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.drop('Review', axis = 1)\ndf = df.drop('Recommends', axis = 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The following functions are for:\n* coverting uppercase to lowercase\n* removing punctuation marks\n* removing non-ascii characters such as emojis, special characters etc."},{"metadata":{"trusted":true},"cell_type":"code","source":"def lower_case(txt):\n    return txt.lower()\n\ndef remove_punctuation(txt):\n    txt_clean = \"\".join([c for c in txt if c not in string.punctuation])\n    return txt_clean\n\ndef remove_non_ascii_chars(txt):\n    txt_fullclean = \"\".join(i for i in txt if ord(i)<128)\n    return txt_fullclean","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*Applying each function at a time and storing the new texts in seperate columns*"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['lower_case_review'] = df['Review Text'].apply(lambda x: lower_case(x))\ndf['punctuation_free_review'] = df['lower_case_review'].apply(lambda x: remove_punctuation(x))\ndf['clean_review'] = df['punctuation_free_review'].apply(lambda x: remove_non_ascii_chars(x))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*As the 'clean_review' column has the most cleaned text I am keeping this column only in the same dataframe.*"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df[['clean_review']]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*Now let's check the SentimentIntensityAnalyzer tool from nltk and test it on a single review.*"},{"metadata":{"trusted":true},"cell_type":"code","source":"s_i_a = SentimentIntensityAnalyzer()\n\nprint(df['clean_review'][50])\ns_i_a.polarity_scores(df['clean_review'].iloc[50])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*The result looks decent.*\n*let's apply it on all the review texts.*"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['polarity_score'] = df['clean_review'].apply(lambda x: s_i_a.polarity_scores(x))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*The compound score is a better indicator of positive and negative sentiment in this case. So I am going to store it in seperate column.*"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['compound_score'] = df['polarity_score'].apply(lambda x: x['compound'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*Here I am choosing 0.20 as the threshold value for compound score.*"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['sentiment_tag'] = df['compound_score'].apply(lambda x: 'positive' if x>0.20 else 'negative')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['sentiment_tag'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sb.set(rc={'figure.figsize':(7.5,4.27)})\n\nsb.countplot(x = 'sentiment_tag', data = df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**The dataset is asymmetric as the number of positive reviews are more than two times of negative reviews.**"},{"metadata":{},"cell_type":"markdown","source":"*Let's manually label the existing two tags.*"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['labels'] = df['sentiment_tag'].apply(lambda x: 0 if x == 'negative' else 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.drop('polarity_score', axis = 1)\ndf = df.drop('compound_score', axis = 1)\ndf = df.drop('sentiment_tag', axis = 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*Coverting the reviews and the labels to numpy arrays for further preprocessing.*"},{"metadata":{"trusted":true},"cell_type":"code","source":"(X, y) = (df['clean_review'].values, df['labels'].values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Type of X: \", type(X), \"\\nType of y: \",type(y))\nprint(\"\\nShape of X: \",X.shape, \"\\nShape of y: \", y.shape)\nprint(\"\\nExample:\", X[0], '=', y[0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Tokenization & Padding"},{"metadata":{},"cell_type":"markdown","source":"*Declaring all the necessary variables for tokenization:*"},{"metadata":{"trusted":true},"cell_type":"code","source":"max_length = 100\nembedding_dim = 50\ntrunc_type='post'\npadding_type='post'\noov_token = \"<OOV>\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tokenizer = Tokenizer(oov_token = oov_token)\ntokenizer.fit_on_texts(X)\n\nword_index = tokenizer.word_index\nvocab_size = len(word_index)\n\nX_seq = tokenizer.texts_to_sequences(X)\nX_padded = pad_sequences(X_seq, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n\nprint('Vocab Size = ', vocab_size)\nprint(X_padded[0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*Spliting the tokenized values into train and test sets:*"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_padded, test_padded, train_label, test_label = train_test_split(X_padded, y, test_size = 0.15, random_state = 10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*Let's convert these values into numpy arrays to feed into neural network.*"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_padded = np.array(train_padded)\ntest_padded = np.array(test_padded)\ntrain_label = np.array(train_label)\ntest_label = np.array(test_label)\n\nprint(train_padded.shape, test_padded.shape, train_label.shape, test_label.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"embeddings_index = dict()\nf = open('../input/glove6b50dtxt/glove.6B.50d.txt')\nfor line in f:\n    values = line.split()\n    word = values[0]\n    coefs = np.asarray(values[1:], dtype='float32')\n    embeddings_index[word] = coefs\nf.close()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"embedding_matrix = np.zeros((vocab_size, 50))\nfor word, index in tokenizer.word_index.items():\n    if index > vocab_size - 1:\n        break\n    else:\n        embedding_vector = embeddings_index.get(word)\n        if embedding_vector is not None:\n            embedding_matrix[index] = embedding_vector","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\nmodel.add(Embedding(vocab_size, embedding_dim, input_length = max_length, weights = [embedding_matrix], trainable = False))\nmodel.add(SpatialDropout1D(0.4))\nmodel.add(LSTM(128, return_sequences = True, input_shape = train_padded.shape))\nmodel.add(LSTM(64, dropout = 0.2, recurrent_dropout = 0.2))\nmodel.add(Dense(1, activation = 'sigmoid'))\n\nmodel.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n\nprint(model.summary())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"num_epochs = 5\n\nhistory = model.fit(train_padded, train_label, epochs=num_epochs, validation_data=(test_padded, test_label), verbose=2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Visualizing performance"},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n\nacc=history.history['accuracy']\nval_acc=history.history['val_accuracy']\nloss=history.history['loss']\nval_loss=history.history['val_loss']\n\nepochs=range(len(acc))\n\n\nplt.plot(epochs, acc, 'r')\nplt.plot(epochs, val_acc, 'b')\nplt.title('Training and validation accuracy')\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Accuracy\")\nplt.legend([\"Accuracy\", \"Validation Accuracy\"])\n\nplt.figure()\n\n\nplt.plot(epochs, loss, 'r')\nplt.plot(epochs, val_loss, 'b')\nplt.title('Training and validation loss')\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")\nplt.legend([\"Loss\", \"Validation Loss\"])\n\nplt.figure()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}